

# 机器学习

## 训练数据切分

### 留出法

留出法(hold-out)：直接将数据切分成三个互斥的部分，即训练集、测试集和验证集。在训练集上训练模型，在测试集上选择模型，最后在测试集上评估泛化误差。数据集的划分要尽量保持数据分布的一致性，如在分类任务中至少要保持样本的类别比例相似，此时可以采用分层采样。 

```python
>>> import numpy as np
>>> from sklearn.model_selection import train_test_split
>>> X, y = np.arange(10).reshape((5, 2)), range(5)
>>> X
array([[0, 1],
       [2, 3],
       [4, 5],
       [6, 7],
       [8, 9]])
>>> list(y)
[0, 1, 2, 3, 4]
>>> X_train, X_test, y_train, y_test = train_test_split(
...     X, y, test_size=0.33, random_state=42)
...
>>> X_train
array([[4, 5],
       [0, 1],
       [6, 7]])
>>> y_train
[2, 0, 3]
>>> X_test
array([[2, 3],
       [8, 9]])
>>> y_test
[1, 4]
>>> train_test_split(y, shuffle=False)
[[0, 1, 2], [3, 4]]
```

### K折交叉验证

```python
>>> from sklearn.model_selection import cross_val_score
>>> clf = svm.SVC(kernel='linear', C=1)
>>> scores = cross_val_score(clf, iris.data, iris.target, cv=5)
>>> scores                                              
array([ 0.96...,  1.  ...,  0.96...,  0.96...,  1.        ])
```

### 留一法

当K折交叉验证中的K等于样本个数即为留一法

```python
>>> from sklearn.model_selection import LeaveOneOut

>>> X = [1, 2, 3, 4]
>>> loo = LeaveOneOut()
>>> for train, test in loo.split(X):
...     print("%s %s" % (train, test))
[1 2 3] [0]
[0 2 3] [1]
[0 1 3] [2]
[0 1 2] [3]
```

### 自助法(bootstrap)

有放回采样，这种采样方法采样会有约36.8%的样本不出现

$\lim\limits_{m \to \infty}(1-\frac{1}{m})^{m}   \to \frac{1}{e} \approx 0.368$

此种做法数据集与原数据集同规模，但数据分布有所变化。

包外估计(out-of-bag estimation): 用没有采集到的数据用做测试集

```python
train = data.sample(frac=1.0,replace=True)
test = data.loc[data.index.difference(train.index)].copy()
```

## 模型评估指标

### 回归模型评估

#### 均方误差 MSE

$MSE=\frac{1}{m}\sum\limits^{m}_{i=1}(f(x_{i})-y_{i})^{2}$

用于评估回归模型

```python
>>> from sklearn.metrics import mean_squared_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> mean_squared_error(y_true, y_pred)
0.375
```

#### 平均绝对误差 MAE

$MAE=\frac{1}{m}\sum\limits^{m}_{i=1}|f(x_{i})-y_{i}|$

```python
>>> from sklearn.metrics import mean_absolute_error
>>> y_true = [3, -0.5, 2, 7]
>>> y_pred = [2.5, 0.0, 2, 8]
>>> mean_absolute_error(y_true, y_pred)
0.5
```

#### 均方根误差 RMSE

$RMSE=\sqrt{MSE}$

#### R平方(决定系数)

反应因变量的全部变异（方差）能通过回归关系被自变量解释的比例

$r^2=1-\frac{SS_{res}}{SS_{tot}}=1-\frac{\sum(y_i-f_i)^2}{\sum(y_i-\overline y)^2}$

​     $ = 1-\frac{MSE(\hat y, y)}{var(y)}$



### 分类模型评估

#### 错误率

$E(f;D)=\frac{1}{m}\sum\limits^{m}_{i=1}I(f(x_{i})\neq y_{i})$

#### 精度

样本不均衡时失效

$acc(f;D)=\frac{1}{m}\sum\limits^{m}_{i=1}I(f(x_{i})=y_{i})$

​                 $= 1-E(f;D)$

```python
>>> import numpy as np
>>> from sklearn.metrics import accuracy_score
>>> y_pred = [0, 2, 1, 3]
>>> y_true = [0, 1, 2, 3]
>>> accuracy_score(y_true, y_pred)
0.5
>>> accuracy_score(y_true, y_pred, normalize=False)
2
```

#### 混淆矩阵(二分类)

|      |  预测为正例  |  预测为反例  |
| :--: | :----------: | :----------: |
| 正例 | TP（真正例） | FN（假反例） |
| 反例 | FP（假正例） | TN（真反例） |

查准率（准确率）：

$P=\frac{TP}{TP+FP}$

所有预测为正例的样本中，预测对的比例

```python
>>> from sklearn.metrics import precision_score
>>> y_true = [0, 1, 2, 0, 1, 2]
>>> y_pred = [0, 2, 1, 0, 0, 1]
# 当只有两个类别时，不用配置average参数默认为binary
>>> precision_score(y_true, y_pred, average='macro')  
0.22...
```

查全率（召回率）：

$R = \frac {TP}{TP+FN}$

所有的正样本中，被预测正确的比例

```python
>>> from sklearn.metrics import recall_score
>>> y_true = [0, 1, 2, 0, 1, 2]
>>> y_pred = [0, 2, 1, 0, 0, 1]
# 当只有两个类别时，不用配置average参数默认为binary
>>> recall_score(y_true, y_pred, average='macro')  
0.33...
>>> recall_score(y_true, y_pred, average='micro')  
0.33...
>>> recall_score(y_true, y_pred, average='weighted')  
0.33...
>>> recall_score(y_true, y_pred, average=None)
array([ 1.,  0.,  0.])
```

#### F1值

综合考虑准确率和召回率的一项及指标，它是两个指标的几何平均值

$F1 = \frac {2}{\frac{1}{P}+\frac{1}{R}}$

​      $=\frac{2\times P\times R}{P+R}=\frac{2\times TP}{样例总数+TP-TN}$

```python
>>> from sklearn.metrics import f1_score
# 当只有两个类别时，不用配置average参数默认为binary
>>> y_true = [0, 1, 2, 0, 1, 2]
>>> y_pred = [0, 2, 1, 0, 0, 1]
>>> f1_score(y_true, y_pred, average='macro')  
0.26...
>>> f1_score(y_true, y_pred, average='micro')  
0.33...
>>> f1_score(y_true, y_pred, average='weighted')  
0.26...
>>> f1_score(y_true, y_pred, average=None)
array([ 0.8,  0. ,  0. ])
```



$F_{\beta}=\frac{(1+\beta^2)\times P\times R}{(\beta^2\times P)+R}$

$\beta>1$时查全率有更大的影响；$\beta<1$时查准率有更大的影响

```python
>>> from sklearn.metrics import fbeta_score
# 当只有两个类别时，不用配置average参数默认为binary
>>> y_true = [0, 1, 2, 0, 1, 2]
>>> y_pred = [0, 2, 1, 0, 0, 1]
>>> fbeta_score(y_true, y_pred, average='macro', beta=0.5)
... 
0.23...
>>> fbeta_score(y_true, y_pred, average='micro', beta=0.5)
... 
0.33...
>>> fbeta_score(y_true, y_pred, average='weighted', beta=0.5)
... 
0.23...
>>> fbeta_score(y_true, y_pred, average=None, beta=0.5)
... 
array([ 0.71...,  0.        ,  0.        ])
```

#### ROC曲线 & AUC 

在二分类问题中，会根据不同的阈值区分正例和反例，ROC即是在取不同阈值的情况下分别计算TPR和FPR

![](D:\github\notebook\images\AUC.png)

+ X轴，为FPR：在所有负样本中，分类预测错误的比例

  $FPR = \frac{FP}{FP+TN}$

+ Y轴，为TPR：在所有正样本中，分类预测正确的比例（等于召回率RECALL）

  $TPR=\frac{TP}{TP+FN}$

```python
# roc曲线参数计算
>>> import numpy as np
>>> from sklearn import metrics
>>> y = np.array([1, 1, 2, 2])
>>> scores = np.array([0.1, 0.4, 0.35, 0.8])
>>> fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)
>>> fpr
array([ 0. ,  0.5,  0.5,  1. ])
>>> tpr
array([ 0.5,  0.5,  1. ,  1. ])
>>> thresholds
array([ 0.8 ,  0.4 ,  0.35,  0.1 ])
```

计算AUC

物理意义：正样本预测结果大于负样本预测结果的概率

方法1：在ROC结果的基础上计算

```python
>>> import numpy as np
>>> from sklearn import metrics
>>> y = np.array([1, 1, 2, 2])
>>> pred = np.array([0.1, 0.4, 0.35, 0.8])
>>> fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)
>>> metrics.auc(fpr, tpr)
0.75
```

方法2：根据预测结果直接结算

```python
>>> import numpy as np
>>> from sklearn.metrics import roc_auc_score
>>> y_true = np.array([0, 0, 1, 1])
>>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])
>>> roc_auc_score(y_true, y_scores)
0.75
```

## 回归模型

### 线性回归

损失函数

$J(\theta_0,\theta_1,...,\theta_n)=\frac{1}{2m}\sum\limits_{i=1}^m(h_{\theta}(x^{(i)})-y^{(i)})^2$

学习算法（梯度下降、最小二乘）

过拟合；欠拟合；

正则化

$J(\theta)=\frac{1}{2m}[\sum\limits^m_{j=1}(h_\theta(x^{(i)})-y^{(i)})^2+\lambda\sum\limits^n_{j=1}\theta^2_j]$

```python
>>> from sklearn.linear_model import Ridge
>>> import numpy as np
>>> n_samples, n_features = 10, 5
>>> np.random.seed(0)
>>> y = np.random.randn(n_samples)
>>> X = np.random.randn(n_samples, n_features)
>>> clf = Ridge(alpha=1.0)  # ridge回归似乎是通过最小二乘求解，无需设置学习率
>>> clf.fit(X, y) 
Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,
      normalize=False, random_state=None, solver='auto', tol=0.001)
```





### 广义线性回归

对线性映射的结果进行数学变换，去逼近y，即通过指数（exp）或者对数（log）变换处理



## 分类模型

### 逻辑回归

sigmoid 函数

![](D:\github\notebook\images\sigmoid.png)

sigmoid函数将原来的线性回归得到的曲线转化为决策边界

损失函数：

因为使用MSE会导致损失函数非凸，因此不用

对数损失/二元交叉熵损失

对数损失是原来计算概率结果的预测函数推导出来的对数似然函数

其物理意义可以分开看

$cost(h_\theta(x),y) = \begin{cases} \qquad -log(h_\theta(x)) \quad if\; y=1\\ \; -log(1-h_\theta(x)) \quad if\ y=0\end{cases}$

因此损失函数推导

$J(\theta) = \frac{1}{m} \sum\limits^m_{i=1}Cost(h_\theta(x^{(i)}), y^{(i)})$

​         $=-\frac{1}{m}[\sum\limits^m_{i=1}y^{(i)}log\ h_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]$

添加正则化项

  $J(\theta)=-\frac{1}{m}\bigg[\sum\limits^m_{i=1}y^{(i)}log\ h_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))\bigg]+\frac{\lambda}{2m}\sum\limits^n_{j=1}\theta^2_j$

```

```

### 决策树

划分叶子节点的三个停止条件

+ 当前结点包含的样本全属于同一类别，无需划分
+ 当前属性集为空（属性划分完了），或者所有样本在所有属性上取值相同（同属性值），无法划分
+ 当前结点包含的样本集合为空（没有样本了），不能划分

#### 信息熵（entropy）

假定当前样本集合D中第k类样本所占的比例为$p_k$, 则D的信息熵定义为：

$Ent(D) = - \sum\limits^{|y|}_{k=1}p_k\ log_2p_k$

$Ent(D)$的值越小，则$D$的纯度越高，$Ent(D)$的最小值为0，最大值为$log_2|y|$（此时所有类别的概率都相当，且$p_k = \frac{1}{|y|}$)

#### 信息增益

information gain, 在ID3中使用

离散属性a的取值为$\{a^1,a^2,a^3,...,a^v\}$ ，$D^v:D$ 在属性 a 上取值为$a^v$的样本集合。则属性a的信息增益：

$Gain(D,a) = Ent(D) - \sum\limits^V_{v=1}\frac{|D^v|}{|D|}Ent(D^v)$

缺点：对属性内取值较多的属性有偏好，比如编号

#### 信息增益率

gain ratio   C4.5中使用

$Gain\_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}$

其中 $IV(a)=-\sum\limits^V_{v=1}\frac{|D^v|}{|D|}log_2\frac{|D^v|}{|D|}$

属性a的可能取值数目越多（即V越大），则IV(a)的值通常就越大。

启发式：先从候选划分属性中找出信息增益高于平均水平的，再从中选取增益率最高的。

#### 基尼指数

gini index：CART树中使用，二分类树模型

$Gini(D)=\sum\limits^{|y|}_{k=1}\sum\limits_{k'\neq k}p_kp_{k'}=1-\sum\limits^{|y|}_{k=1}p^2_k$

$Gini(D)$越小，数据集D的纯度越高

属性a的基尼指数：

$Gini\_index(D,a)=\sum\limits^V_{v=1}\frac{|D^v|}{|D|}Gini(D^v)$

在候选属性集合中，选取那个使划分后基尼指数最小的属性

#### 剪枝

基本策略：

+ 预剪枝(pre-pruning)：提前终止某些分支的生长
+ 后剪枝(post-pruning)：生成一颗完全树，再“回头”剪枝

通过留出法在验证集上测试，逐个节点验证剪枝