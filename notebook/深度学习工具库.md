tensorflow分布式训练

https://blog.csdn.net/hjimce/article/details/61197190?tdsourcetag=s_pctim_aiomsg



## 第一章 Caffe 工具库



官网地址：caffe.berkeleyvision.org

安装：

ubuntu1.7以上可直接安装

1.7以下版本则下载源码安装

​	首先拷贝Makefile.config.example一份 并改名为Makefile.config

​	vim Makefile.config，可以看到对应的配置关于CUDA，GPU环境的地址，基本的设定，依赖到的一些工具库或者library，地址等等，比如只想编译CPU的版本，是否要和python工具一起编译

```
# make all -j32
```

`-j32`指做并行编译 

编译过之后会在目录下生成tools文件夹，里面存放一些工具；在build/tools/文件夹下会有编译好的一些工具，在文件目录下执行`./caffe` 可以进入命令行工具；

`# ./extract_features `会有该工具的说明

`# ./convert_imageset`格式转换，数据不是从原始形态读进来的，会转存到`leveldb`,`lmdb`当中





在caffe目录下的example文件夹下有例子，比如mnist

比如`train_lenet.sh` 是一个shell脚本， 利用caffe命令直接做训练

```
set -e
./build/tools/caffe train --solver=examples/mnist/lenet_solver.prototxt $@
~
~
..
```

然后再打开`lenet_solver.prototxt`

```
net: "examples/mnist/lenet_train_test.prototxt" 
```

表示引号当中的文件规定网络的结构

```
test_iter: 100
test_interval: 500
```

规定迭代轮次，每经过500次训练进行一次测试，每次测试100个样本

```
base_lr:0.01  //规定整个网络的学习率，还要和单层的学习率做乘法才能得到最终的学习率
momentum: 0.9  //momentum超参数
weight_decay: 0.0005   //衰减率
lr_policy:"inv"  //学习率的变化规则，如何衰减
solver_mode: GPU   //使用GPU完成训练
snapshot: 5000  //每隔5000存储一次模型
snapshot_prefix: "examples/mnist/lenet"    //模型文件名前缀
type: "Adam"
display: 100	//展示信息的频次，经过多少batch显示一次 
max_iter: 60000		//最多的迭代轮次
gamma: //lr衰减系数
stepsize: //多久进行一次lr衰减

```

`lenet_train_test.prototxt` 规定了网络结构

```
name: "LeNet"
layer{
    name: "mnist"     //这一层的名字
    type: "Data"	//层类型
    top: "data"		//输出数据
    top: "label"	//输出标签
    include {
        phase: TRAIN			//该层训练阶段使用
    }
    transform_param {
        scale: 0.00390625		// 幅度缩放，1/225 
    }
    data_param {
        source: "examples/mnist/mnist_train_lmdb" 	//数据来源 
        batch_size:64
        backend: LMDB
    }
}
layer {
    name: "mnist"
    type: "Data"
    top: "data"
    top: "label"
    include {
        phase: TEST
    }
    transform_param {
    	scale: 0.00390625
    }
    data_param {
        source: "examples/mnist/mnist_test_lmdb"
        batch_size: 100
        backend: LMDB
    }
}
layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"	//输入
    top: "conv1"	//输出
    param {
        lr_mult: 1		//weight的学习率， 与全局的学习率相乘即为最终的学习率
    }
    param {
        lr_mult: 2		//bias的学习率，与全局的学习率相乘即为最终的学习率
    }
    convolution_param {
        num_output: 20
        kernel_size: 5
        stride: 1
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
        }
    }
}
layer {
    name: "pool1"
    type: "Pooling"
    bottom: "conv1"
    top: "pool1"
    pooling_param {
        pol: MAX
        kernel_size: 2
        stride:2
    }
}
layer {
    name: "conv2"
    type: "Convolution"
    bottom: "pool1"	//输入
    top: "conv2"	//输出
    param {
        lr_mult: 1		//weight的学习率， 与全局的学习率相乘即为最终的学习率
    }
    param {
        lr_mult: 2		//bias的学习率，与全局的学习率相乘即为最终的学习率
    }
    convolution_param {
        num_output: 50
        kernel_size: 5
        stride: 1
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
        }
    }
}
...
layer {
    name: "ip2"
    type: "InnerProduct"	//全连接层
    bottom: "ip1"
    top: "ip2"
    param {
        lr_mult: 1
    }
    param {
        lr_mult: 2
    }
    inner_product_param {
        num_output: 10   //10分类结果
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
        }
    }
}
layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "ip2"
    bottom: "label"
    top: "accuracy"
    include {
        phase: TEST
    }
}
layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "ip2"
    bottom: "label"
    top: "loss"
}
```



`caffe/data`文件夹下已经有 mnsit数据集文件夹

里面有

```
get_minst.sh t10k-image-idx3-ubyte t10k-labels-idx1-ubyte train-image-idx3-ubyte train-labels-idx1-ubyte
```

通过脚本从网上拉下来的数据

通过`bash get_mnist.sh` 来执行





在执行例子进行训练之前要运行`create_mnist.sh`， 将数据转成lmdb形式

```
set -e
EXAMPLE=examples/mnist
DATA=data/mnist
BUILD=build/examples/mnist

BACKEND="lmdb"

echo "Creating ${BACKEND}..."

rm -rf $EXAMPLE/mnist_train_${BACKEND}
rm -rf $EXAMPLE/mnist_test_${BACKEND}

$BUILD/convert_mnist_data.bin $DATA/train-image-idx3-ubyte \
  $DATA/train-labels-idx1-ubyte $EXAMPLE/mnist_train_${BACKEND} --backend=${BACKEND}
$BUILD/convert_mnist_data.bin $DATA/t10k-image-idx3-ubyte \
  $DATA/t10k-labels-idx1-ubyte $EXAMPLE/mnist_test_${BACKEND} --backend=${BACKEND}

echo "Done."

```

运行脚本

```
bash create_mnist.sh
。/examples/mnist/create_mnist.sh
```

执行训练

```
./examples/mnist/train_lenet_adam.sh
```

训练之后会生成模型文件`lenet_iter_10000.caffemodel`



数据转化`./build/tools/convert_imageset.bin  `

`可后续加参数-backend lmdb` 

```
convert_imageset [FLAGS] ROOTFOLDER(图像存储路径)/LISTFILE（绝对路径和类别） DB_NAME(数据库文件名称)
```



总结： 使用CAFFE完成神经网络训练操作步骤（命令行的方式）：

- 原始数据转换：写数据转换脚本 转换成lmdb, leveldb， 原始数据是图片如（jpg  png  tif）等大量散碎文件，lmdb,leveldb是特殊的二进制数据文件，对计算机读写操作有极大的优化

```
// HDFS-5数据格式输入的示例（来自caffe官方）
name: "LogisticRegressionNet"
layer {
    name: "data"
    type: "HDF5Data"
    top: "data"
    top: "label"
    include {
        phase: TRAIN
    }
    hdf5_data_param {
        source: "examples/hdf5_classification/data/train.txt"
        batch_size: 10
    }
}
```



- 定义网络层：  按指定格式写prototxt文件

 ```
name: "LogisticRegressionNet"
layers {
    top: "data"			//定义输出数据
    top: "label"		//定义层输出数据
    name: "data"
    type: HDF5_DATA
    hdf5_data_param {
        source: "examples/hdf5_classification/data/train.txt"
        batch_size: 10
    }
    include {
        phase: TRAIN
    }
}
layers {
    bottom: "data"
    top: "fc1"
    name: "fc1"
    type: INNER_PRODUCT  //全连接层
    blobs_lr: 1     //w 学习率
    blobs_lr: 2		//b 学习率
    weight_decay: 1		//Regularization weight
    weight_decay: 0		//... bias
    inner_product_param {
        num_output: 2
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}
layers {
    bottom: "fc1"
    bottom: "label"
    top: "loss"
    name: "loss"
    type: SOFTMAX_LOSS
}
 ```

可能出现的问题：

prototxt文件可能因为模型较大，层次较深而变得十分臃肿

不能文件组合，复杂网络很难定义

直到caffe2，才有RNN的网络定义版本



- solver定义：按指定格式写prototxt文件，定义优化参数和算法

- 训练：写一个训练脚本

```
./build/tools/caffe train \
	gpu 0 \			// gpu设备号
	model path/to/trainval.prototxt	\	// 网络模型设计文件
	solver path/to/solver/prototxt \	// 模型优化文件
	weight path/to/pretrained_weights.caffemodel	//预训练模型
```



项目示例

caffe里提供modelzoo里有非常多的训练好的模型

新加层次调大学习率

```
layers {
    name: "fc8_oxford102"
    type: INNER_PRODUCT
    bottom: "fc7"
    top: "fc8_oxford102"
    blobs_lr:10
    blobs_lr:20
    weight_decay:1
    weight_decay:0
    inner_product_param {
        num_output:102
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}
layers {
    name: "loss"
    type: SOFTMAX_LOSS
    bottom: "fc8_oxford102"
    bottom: "label"
}
layers {
    name: "accuracy"
    ...
}
```

caffe-oxford102文件夹是包含以下文件

```
README.ipynb 
README.md 
VGG_S 				//
boottrap.py 		//从网上把数据下载下来的python代码
classs_labels.py 
data plots 
test.txt 
train.txt 
valid.txt
```

bootstrap.py

```python
import os
import sys
import glob
import urllib.request as rq
import tarfile
import numpy as np

def download_file(url, dest=None):
    if not dest:
        dest = 'data/' + url.split('/')[-1]
    rq.urlretrieve(url, dest)
    
# Download the oxford102 dataset into the current directory
if not os.path.exist('data'):
    os.mkdir('data')
    
    print('Sownloading images...')
    download_file('http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flower.tgz')
    tarfile.open("data/102flower.tgz").extractall(path='data/')
    
    print("Downloading image labels...")
    download_file("http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat")
    
    print("Downloading train/test/valid splits...")
    download_file('http://www.robots.ox.ac.uk/~vgg/data/flowers/102/setid.mat')
    
# Read .mat file containing training, testing, and validation sets.
setid = loadmat('data/setid.mat')

print(setid)
# The .mat file is 1-indexed, so we subtract one to match Caffe's convention.
idx_train = setid['trnid'][0] - 1
idx_test = setid['tstid'][0] - 1
idx_valid = setid['valid'][0] - 1

# Read .mat file containing image labels.
image_labels = loadmat('data/imagelabels.mat')['labels'][0]
# Subtract one to get 0-based labels
image_labels -= 1

files = sorted(glob.glob('data/jpg/*.jpg'))  # 读取通配符路径，排序？
labels = np.array(list(zip(files, image_labels)))

# Get current working directory for making absolute paths to images
cwd = os.path.dirname(os.path.relpath(__file__))

def write_set_file(fout, labels):
    with open(fout, 'w+') as f:
        for label in labels:
            f.write('%s/%s %s\n' % (cwd, label[0], label[1]))
            
# Images are orderd by species, so shuffle them
np.random.seed(2018)
idx_train = idx_train[np.random.permutation(len(idx_train))]
idx_test = idx_test[np.random.permutation(len(idx_test))]
idx_valid = idx_valid[np.random.permutation(len(idx_valid))]

write_set_file('train.txt', labels[idx_train, :])
write_set_file('test.txt', labels[idx_test, :])
write_set_file('valid.txt', labels[idx_valid, :])

# if not os.path.exists("AlexNet/pretrained-weights.caffemodel"):
#     print('Downloading Alexnet pretrianed wights...')
#     download_file('http://s3.amazonaws.com/jgoode/cannaid/bvlc_ref...cafemodel',
#                   'AlexNet/pretrained0weights.caffemodel')

if not os.path.exists("AlexNet/pretrained-weights.caffemodel"):
    print('Downloading Alexnet pretrianed wights...')
    download_file('http://www.robots.ox.ac.uk/~vgg/software/deep_eval/releases/bvlc/VGG_CNN_S.cafffemodel','VGG_S/pretrained-weights.caffemodel')
```

VGG_S文件夹下有以下文件

```
deploy.prototxt
log-flipped.txt
log.txt
pretrained-weights.caffemodel
solver.prototxt
train_val.prototxt 
```

通过bootstrap.py 下载下来的data 目录下

```
102flowers.tgz
imagelabels.mat
jpg
setid.mat
```

通过bootstrap.py构建的train.txt test.txt valid.txt 格式为

“图片路径加文件名称  类别号”

执行训练

```
../caffe/build/tools/caffe train -solver sover.prototxt -weights pretrained-weights.caffemodel -gpu 0
```

网络结构配置文件定义了，均值化要根据一个均值配置文件，所以提示缺少均值文件

```
bash get_ilsvrc_aux.sh
之后下载下来imagenet_mean.binaryproto均值文件
cp src dest  
拷贝到当前目录下

```

发现内存占用太大

查看显存使用情况

```
nvidia-smi
```

关闭多余进程

```
kill -9 5340(PID号)
```

减少全连接层



使用caffe工具库抽取特征

命令方式：

1. Caffe 提供了为了提取特征而设计的网络结构样例， 仿照它写一个特征抽取网络(./examples/feature_extraction/imagenet_val.prototxt)
2. 调用Caffe框架里有特征抽取的命令（./build/tools/extract_features.bin)

```
extract_features.bin \
pretrained_net_param \ # 实现训练好的网络参数，具体的文件是bvlc_reference_caffemodel(caffe龚恒自带)
feature_extraction_proto_file  \ # 网络配置原型就是上面更改的.prototxt文件
extract_feature_blob_name1[,name2,...] \ # 表示特顶层的特征，比如fc7,conv5,pool5,这个需要和上面的.prototxt文件定义的一致
save_feature_dataset_name1[,name2,...] \ # 表示需要存储提取到的特征目录，这个目录由程序自动创建
num_mini_batches \ # 为批次处理个数，这个乘以.prototxt里面配置的batch_size得到的就是总共需要提取的图片的个数
db_type \ # 表示提取到的特征按照什么方式存储，目前有两种方式，lmdb和leveldb
[CPU/GPU][DEVICE_ID=0]  # 默认CPU，后面可以指定GPU以及具体的GPU个数
```

3. 对某一层的特征，可直接保存下来

```
feat_fc6 = net.blobs['fc6].data[0]
feat_fc6.shape = (4096,1)
row_feat_fc6 = numpy.transpose(feat_fc6)
numpy.savetxt(./caffe/examples/_temp/ +"features.txt", row_feat_fc6)
scipy.io.savemat(./caffe/examples/_temp/ + "feature.mat", {'feature':row_feat_fc6})
```



抽取特征的过程

执行`./build/tools/extract_features.bin` 可以看到使用方法介绍，例

```
./build/tools/extract_features.bin examples/mnist/lenet_iter_10000.caffemodel examples/mnist/lenet_train_test.prototxt ip2 examples/features 10 lmdb GPU 0
```







## 第二章  Keras 工具库

高层封装神经网络API

纯Python编写

利用tensorflow Theano  CNTK  mxnet作为后端计算，通过 keras.json文件配置

引入库， 初始化“模型架子”

```python
from keras.models import Sequential
model = Sequential()
```

通过add来添加层

```python
from keras.layers import Dense, Activation

model.add(Dense(units=64, input_dim=100))  # 全连接层
model.add(Activation('relu'))   # 激活层
model.add(Dense(units=10))
model.add(Activation('softmax'))
```

通过compile来编译模型

```python
model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])
```

编译模型时必须指明损失函数和优化器，如果你需要的话，也可以自己定制损失函数。Keras里也封装了很多优化器和损失函数

```python
from keras.optimizers import SGD
model.compile(loss='categorical_crossentropy', optimizer=SGD(LR=0.01, momentum=0.9, nesterov=True))
```

训练模型

```
model.fit(x_train, y_train, epochs=5, batch_size=32)
```

手动一批一批数据训练

```
model.train_on_batch(x_batch, y_batch)
```

在测试集上评估效果

```
loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)
```

实际预测

```
classes = model.predict(x_test, batch_size=128)
```





### Keras 序贯模型

简单的堆叠

可以通过向Sequential 模型传递一个layer的list来构建序列模型，或者通过.add()方法一个个的将layer加入模型

```python
# 一次性构建
from keras.models import Sequential
from keras.layers import Dense, Activation

model = Sequential([
    Dense(32, input_dim=784),
    Activation('relu'),
    Dense(10),
    Activation('softmax'),
])
```

手动添加

```python
model = Sequential()
model.add(Dense(32, input_shape=(784,)))
model.add(Activation('relu'))
```

告诉模型输入数据的维度



编译模型：`compile`接收三个参数：

- 优化器optimizer
- 损失函数loss   https://keras-cn.readthedocs.io/en/latest/other/objectives/
- 指标列表metrics

```python
# 多分类问题
model.compile(
    optimizer='rmsprop',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
# 二分类问题
model.compile(
    optimizer='rmsprop',
    loss='binary_crossentropy',
    metrics=['accuracy']
)
# 回归问题
model.compile(
    optimizer='adagrad',
    loss='mse'
)

# 自定义metrics
import keras.backend as K

def mean_pred(y_true, y_pred):
    return K.mean(y_pred)

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy', mean_pred])
```

训练

如果一次性读进内容进行建模

```python
# 构建与编译模型
model = Sequential()
model.add(Dense(32, activation='relu', imput_dim=100))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])

# 查出数据
import numpy as np
data = np.random.random((1000, 100))
labels = np.random.randint(2, size=(1000, 1))

# 训练与数据拟合
history = model.fit(data, labels, epochs=10, batch_size=32)
```

如果你的数据量很大， 你可能要用到fit_generator

```python
def generate_array_from_file(path):
    while 1:
        f = open(path)
        for line in f:
            x, y = process_line(line)  # 自己实现，把文件地址转换成输入和标签
            img = load_images(x)
            yield (img, y)  # 返回结果，且不中断循环
        f.close()
        
model.fit_generator(generate_arrays_from_file('/my_file.txt'), samples_per_epoch=10000,
                    nb_epoch=10)
```

序贯模型的例子

多层感知机

```python
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD

# Generate dummy data
import numpy as np
x_train = np.random.random((1000, 20))
y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000,1)), num_classes=10)
x_test = np.random.random((100,20))
y_test = keras.utils.to_categorical(np.random.randint(10, size=(100,1)), num_classes=10)

model = Sequential()
model.add(Dense(64, activation='relu', input_dim=20))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

model.fit(x_train, y_train, epochs=20, batch_size=128)
score = model.evaluate(x_test, y_test, batch_size=128)
```

卷积神经网络

```python
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.optimizers import SGD

x_train = np.random.random((100, 100, 100, 3))
y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)
x_test = np.random.random((20, 100, 100, 3))
y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)

model = Sequential()
# input: 100x100 images with 3 channels
# this applies 32convolution filters of size 3x3 each.
model.add(Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 3)))
model.add(Conv2D(32, (3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3,3), activation='relu'))
model.add(Conv2D(64, (3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=32, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=32)
```

循环神经网络

```python
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.layers import Embedding
from keras.layers import LSTM

model = Sequential()
model.add(Embedding(max_features, output_dim=256))
model.add(LSTM(128))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
model.fit(x_train, y_train, batch_size=16, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=16)
```

### 函数式模型

MLP的例子

```python
from keras.layers import Input, Dense
from keras.models import Model

inputs = Input(shape=(784,))
x = Dense(64, activation='relu')(inputs)
x = Dense(64, activation='relu')(x)
predictions = Dense(10, activation='softmax')(x)

model = Model(inputs=inputs, outputs=predictions)
model.compile(optimizer='rmsprop',
             loss='categorical_crossentropy',
             metrics=['accuracy'])
model.fit(data, labels)
```

当你调用一个模型时，你不仅仅重用了它的结构，也重用了他的权重

```python
x = Input(shape=(784,))
# 给一个x，就会复用上面的模型，得到y
y = model(x)
```

更复杂的多输入多输出模型

考虑这样一个模型。我们希望预测Twitter上一条新闻会被转发和点赞多少次。 模型的主要输入是新闻本身，也就是一个词语的序列。但我们还可以拥有额外的输入，如新闻发布的日期等。 这个模型的损失函数将由两部分组成，辅助的损失函数评估仅仅基于新闻本身做出预测的情况，主损失函数评估基于新闻和额外信息的预测的情况，即使来自主损失函数的梯度发生弥散，来自辅助损失函数的信息也能够训练`Embeddding`和`LSTM`层。在模型中早点使用主要的损失函数是对于深度网络的一个良好的正则方法。 

主要的输入接收新闻本身，即一个整数的序列（每个整数编码了一个词）。这些整数位于1到10000之间（即我们的字典有10000个词）。这个序列有100个单词。 

```python
from keras.layers import Input, Embedding, LSTM, Dense
from keras.models import Model

# Headline input: meant to receive sequence of 100 integers, between 1 and 10000.
# Note that we can name any layer by passing it a "name" argument.
main_input = Input(shape=(100,), dtype='int32', name='main_input')

# This embedding layer will encode the input sequence
# into a sequence of dense 512-dimensional vectors.
x = Embedding(ouput_dim=512, input_dim=10000, input_length=100)(main_input)

# A LSTM will transform the vector sequence into a single vector, containing information about the entire sequence.
lstm_out = LSTM(32)(x)
```

然后我们插入一个额外的损失，使得即使在主损失很高的情况下，LSTM和Embedding层也可以平滑训练。

```python
auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)
```

再然后，我们将LSTM与额外的输入数据串联起来组成输入，送入模型：

```python
auxiliary_input = Input(shape=(5,), name='aux_input')
x = keras.layers.concatenate([lstm_out, auxiliary_input])

# We stack a deep densely-connected network on top
x = Dense(64, activation='relu')(x)
x = Dense(64, activation='relu')(x)
x = Dense(64, activation='relu')(x)

# And finally we add the main logistic regression layer
main_output = Dense(1, activation='sigmoid', name='main_output')(x)
```

最后我们定义整个2输入2输出模型

```python
model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])
```

模型定义完成，下一步编译模型，我们给额外的损失赋值0.2的权重。我们可以通过关键字参数`loss_weights`或者`loss`来为不同的输出设置不同的损失函数或权值。这两个参数均可为Python的列表或字典。这里我们给loss传递单个损失函数，这个损失函数会被应用于所有输出上。

```python
model.compile(opimizer='rmsprop', loss='binary_crossentropy', loss_weights=[1.0, 0.2])
```

传递训练数据和目标值训练模型

```python
model.fit([headline_data, additional_data], [labels, labels], epochs=50, batch_size=32)
```

因为我们的输入和输出是被命名过的（在定义时传递了“name”参数），我们也可以用下面的方式编译和训练模型

```python
model.compile(optimizer='rmsprop',
             loss={'main_output':'binary_crossentropy', 
                   'aux_output':'binary_crossentropy'},
             loss_weights={'main_output':1.0, 'aux_output':0.2})
model.fit({'main_input':headline_data, "aux_input":additional_data},
         {'main_output':labels, 'aux_output':labels},
         epochs=50, batch_size=32)
```

Google inception

```python
from keras.layers import Conv2D, MaxPooling2D, Input

input_img = Input(shape=(3,256, 256))

tower_1 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)
tower_1 = Conv2D(64, (3,3), padding='same', activation='relu')(tower_1)

tower_2 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)
tower_2 = Conv2D(64, (5,5), padding='same', activation='relu')(tower_2)

tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)
tower_3 = Conv2D(64, (1,1), padding='same', activation='relu')(tower_3)

output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)
```

残差网络 ResNet

```python
from keras.layers import Conv2D, Input

# input tensor for a 3-channel 256x256 image
x = Input(shape=(3,256,256))
# 3x3 conv with 3output channels (same as input channels)
y = Conv2D(3, (3,3), padding='same')(x)
# this return x + y
z = keras.layers.add([x, y])
```

共享视觉模型

该模型再两个输入上重用了图像处理模型，用来判别两个MNIST数字是相同数字

```python
from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten
from keras.models import Model

# First define the vision modules
digit_input = Input(shape=(1, 27, 27))
x = Conv2D(64, (3,3))(digit_input)
x = Conv2D(64, (3,3))(x)
x = MaxPooling2D((2,2))(x)
out = Flatten()(x)

vision_model = Model(digit_input, out)

# Then define the tell-digits-apart model
digit_a = Input(shape=(1, 27, 27))
digit_b = Input(shape=(1, 27, 27))

# The vision model wii be shared, weights and all
out_a = vision_model(digit_a)
out_b = vision_model(digit_b)

concatenated = keras.layers.concatenate([out_a, out_b])
out = Dense(1, activation='sigmoid')(concatenated)

classification_model = Model([digit_a, digit_b], out)
```

视频问答模型

在针对一幅图片使用自然语言进行提问时，该模型能够提供关于该图片的一个单词的答案

这个模型将自然语言的问题和图片分别映射为特征向量，将二者合并后训练一个logistic回归层，从一系列可能的答案中挑选一个。

```python
from keras.layers import Conv2D, MaxPooling2D, Flatten
from keras.layers import Input, LSTM, Embedding, Dense
from Keras.layers import Model, Sequential

# first, let's define a vision model using a Sequential model.
# This model will encode an image into a vector
vision_model = Sequential()
vision_model.add(Conv2D(64, (3,3), activation='relu', padding='same', 
                          input_shape(3,224,224)))
vision_model.add(Conv2D(64, (3,3), activation='relu'))
vision_model.add(MaxPooling2D((2,2)))
vision_model.add(Conv2D(128, (3,3), activation='relu', padding='same'))
vision_model.add(Conv2D(128, (3,3), activation='relu'))
vision_model.add(MaxPooling2D((2,2)))
vision_model.add(Conv2D(256, (3,3), activation='relu', padding='same'))
vision_model.add(Conv2D(256, (3,3), activation='relu'))
vision_model.add(Conv2D(256, (3,3), activation='relu'))
vision_model.add(MaxPooling2D((2,2)))
vision_model.add(Flatten())

# Now let's get a tensor with the output of our vision model:
image_input = Input(shape=(3, 224, 224))
encoded_image = vision_model(image_input)

# Next, let's define a language model to encode the question into a vector. Each question will be at most 100 word long, and we will index words as integers from 1 to 9999.
question_input = Input(shape=(100,), dtype='int32')
embedded_question = Embedding(input_dim=10000, output_dim=256, input_lenth=100)(question_input)
encoded_question = LSTM(256)(embedded_question)

# Let's concatenate the question vector and the image vector:
merged = keras.layers.concatenate([encoded_question, encoded_image])

# And let's train a logistic regression over 1000 words on top:
output = Dense(1000, activation='softmax')(merged)

# This is our final model:
vqa_model = Model(inputs=[image_input, question_input], outputs=output)
```

视频问答模型

在做完图片问答模型后，我们可以快速将其转为视频问答的模型。在适当的训练下，你可以为模型提供一个短视频（如100帧）然后向模型提问一个关于该视频的问题，如"What sport is the boy playing?"->"football"

```python
from keras.layers import TimeDistributed

video_input = Input(shape=(100, 3, 224, 224))
# This is our video encoded via the previously trained vision_model(weights are reused)
# the output will be a sequence of vectors
encoded_frame_sequence = TimeDistributed(vision_model)(video_input)
# the output will be a vector
encoded_video = LSTM(256)(encoded_frame_sequence)

# This is a model-level representation of the question encoder, reusing the same weights as before:
question_encoder = Model(inputs=question_input, outputs=encoded_question)

# Let's use it to encode the question:
video_question_input = Input(shape=(100,), dtype='int32')
encoded_video_question = question_encoder(video_question_input)

# And this is our video question answering model:
merged = keras.layers.concatenate([encoded_video, encoded_video_question])
output = Dense(1000, activation='softmax')(merged)
video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)
```

reference：<https://keras-cn.readthedocs.io/en/latest/>

### Keras多层感知器练习

```python
import numpy as np
import matplotlib as plt
from keras.models import Sequential
from keras.layers.core import Dense, Dropout
from keras.optimizers import SGD
%matplotlib inline

# 数据读取
from keras.datasets import mnist
from keras.utils import np_utils

(x_train, y_train), (x_test, y_test) = nnist.load_data()

x_train = x_train.reshape(60000, 784)
x_test = x_test.reshape(10000, 784)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

# 幅度缩放
x_train /= 255
x_test /= 255

# label的one-hot编码
y_train = np_utils.to_categorical(y_train, 10)
y_test = np_utils.to_categorical(y_test,10)

# 切分训练和测试集
from sklearn.model_selection import train_test_split
xtrain, xval, ytrain, yval = train_test_split(x_train, y_train)

# 模型构建
model = Sequential()
model.add(Dense(512, activation='relu', input_shape=(784,)))
model.add(Dropout(0.2))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001),
             metrics=['accuracy'])

# 模型训练
network_history = model.fit(xtrain, ytrain, batch_size=128, epochs=20, verbose=1,
                           validation_data=(xval, yval))
```

观看模型信息

```
model.summary()
```

打印训练过程信息

```python
def plot_history(network_history):
    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.plot(network_history.history['loss'])
    plt.plot(network_history.history['val_loss'])
    plt.legend(['Training', 'Validation'])
    
    plt.figure()
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.plot(network_history.history['acc'])
    plt.plot(network_history.history['val_acc'])
    plt.legend(['Training', 'Validation'], loc='lower right')
    plt.show()
```

打印模型信息

```python
# 模型输入张量对象
model.input
# 模型输出张良对象
model.output
# 模型层次信息
for layer in model.layers:
    print(layer.name)
    print(layer.trainable)
    print(layer.get_config())
```

抽取中间层次和可视化

```python
model_truncated = Sequential()
model_truncated.add(Dense(512, activation='relu', input_shape=(784,)))
model_truncated.add(Dropout(0.2))
model_truncated.add(Dense(512, activation='relu'))
# 抽取model中的weights，设置到model_truncated模型中
for i, layer in enumerate(model_truncated.layers):
    layer.set_weights(model.layers[i].get_weights())

model_truncated.compile(loss='categorical_crossentropy',optimizer=SGD(),
                       metrics=['accuracy'])

# 抽取特征
hidden_features = model_truncated.predict(xtrain)

# 降维，可视化
from sklearn.manifold import TSNE
tsne = TSNE(n_components=2)
x_tsne = tsne.fit_transform(hidden_features[:1000])

colors = np.array([x for x in 'b-g-r-c-m-y-k-purple-coral-lime'.split('-')])
colors_map = np.argmax(ytrain, axis=1)
colors_map = colors_map[:1000]
plt.figure(figsize=(10,10))
nb_classes = 10
for cl in range(nb_classes):
    indices = np.where(colors_map == cl)
    plt.scatter(x_tsne[indices, 0], x_tsne[indices, 1], c=colors[cl], label=cl)
plt.legend()
plt.show()
```

### Keras深度卷积神经网络

用训练好的模型初始化模型，keras有很多预训练好的模型

https://github.com/keras-team/keras/tree/master/keras/applications

有VGG16, VGG19, ResNet50，Inception v3，Xception，...

从`keras.applications`中导入预训练模型

VGG16

```python
from keras.applications import VGG16
from keras.applications.imagenet_utils import preprocess_input, decode_predictions
import os

vgg16 = VGG16(
    include_top=True,   # 是否要最后一层的权重
    weights='imagenet'
)
vgg16.summary()  # 打印模型结构
```

默认下载的模型`HDF5`文件会被存储在`~/.keras/models/`

```python
from keras.preprocessing import image
import numpy as np
IMAGENET_FOLDER = 'img/imagenet'
img_path = os.path.join(IMGENET_FOLDER, 'xxx.jpeg')

# 加载图片，调整尺寸为224x224
img = image.load_img(img_path, target_size=(224, 224))
# 转换成array数据类型
x = image.img_to_array(img)
# 增加一个数据维度用于表示样本维度
x = np.expand_dims(x, axis=0)
# 根据imagenet数据集，做数据标准化等预处理
x = preprocess_input(x)
print('Input image shape:', x.shape)  # (1, 224, 224, 3)

preds = vgg16.predict(x)
print('Predicted:', decode_predictions(preds))
# Predicted: [[('n07745940', 'strawberry', 0.9857027), ('n07836838', 'chocolate_sauce', 0.0051280526), ('n04332243', 'strainer', 0.003665665), ('n07614500', 'ice_cream', 0.0021994396), ('n04476259', 'tray', 0.0011691322)]]
```

ResNet50

```python
from keras.applications import ResNet50
from keras.applications.resnet50 import identity_block, conv_block
identity_block??  # ??可用于查询介绍
conv_block??
```

可视化卷积核

```python
import numpy as np
import time
from keras.applications import vgg16
from keras import backend as K
from matplotlib.pyplot as plt

# 定义图像尺寸
IMG_WIDTH = 224
IMG_HEIGHT = 224

vgg16 = vgg16.VGG16(weights='imagenet', include_top=False)

# 为了方便，存储模型层次名称和具体层次的对应
from collections import OrderedDict
layer_dict = OrderedDict()
for layer in vgg16.layers[1:]:
    layer_dict[layer.name] = layer

# 读取图片
img_path = os.path.join(IMAGENET_FOLDER, 'strawberry_1157.jpeg')
img = image.load_img(img_path, target_size=(IMG_WIDTH, IMG_HEIGHT))
input_img_data = image.img_to_array(img)
input_img_data = np.expand_dims(input_img_data, axis=0)

# 定义函数取出中间层次的结果
def get_activations(model, layer, input_img_data):
    # 通过K.function定义函数， K.learning_phase()返回true表示训练阶段，false表示test阶段
    activations_f = K.function([model.layers[0].input, K.learning_phase()], 
                               [layer.output,])
    activations = activations_f((input_img_data, False))
	return activations
# 抽取特征
layer_name = 'block1_conv2'
layer = layer_dict[layer_name]
activations = get_activations(vgg16, layer, input_img_data)

print(activations.shape)  # (1, 224, 224, 64)
print(layer.filters)  # 64
activated_img = activations[0]

# 可视化
n = 8
fig = plt.figure(figsize=(20, 20))
for i in range(n):
    for j in range(n):
        idx = (n*i)+j
        ax = fig.add_subplot(n, n, idx+1)
        ax.imshow(activated_img[:,:,idx])
```

迁移学习

```python
import numpy as np
import pandas as pd
from pathlib import Path
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Model
from keras.layers import Input, Flatten, Dense, Dropout
from keras.callbacks import Callback, ModelCheckpoint
from keras.applications.vgg16 import VGG16
from keras.preprocessing import image
from keras.optimizers import SGD
from keras.applications.vgg16 import preprocess_input

# 定义全局变量
IMG_WIDTH, IMG_HEIGHT = 150, 150
TRAIN_DATA_DIR = 'data/train'
VALIDATION_DATA_DIR = 'data/validation'
MODEL_WEIGHTS_FILE = 'vgg16-xfer-tuned-weights.h5'
NB_TRAIN_SAMPLES = 2000
NB_VALIDATION_SAMPLES = 80
NB_EPOCH = 50

# 数据增强
train_datagen = ImageDataGenerator(
    rescale = 1.0/255,
    shear_range=0.2,
    zoom_range=0.2,		# 放大缩小
    horizontal_flip=True  # 水平方向翻折
)
test_datagen = ImageDataGenerator(rescale=1.0/255)

# flow_from_directory 遍历文件夹
train_generator = train_datagen.flow_from_directory(
    TRAIN_DATA_DIR,
    target_size = (IMG_WIDTH, IMG_HEIGHT),
    batch_size=32,
    class_mode='categorical'
)
validation_generator = test_datagen.flow_from_directory(
    VALIDATION_DATA_DIR,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=32,
    class_mode='categorical'
)

model_vgg16_conv = VGG16(weight='imagenet', include_top=False)

# 固定前面层次的权重参数
for layer in model_vgg16_conv.layers[:-4]:
    layer.trainable = False
    
input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))
x = model_vgg16_conv(input)
x = Flatten()(x)
x = Dense(64, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(2, activation='softmax')(x)
model = Model(input=input, output=x)

model.compile(loss='binary_crossentrop', optimizer=SGD(lr=1e-4, momentum=0.9),
             metrics=['accuracy'])

# 存储中间结果
# 保存验证机结果最高的模型
callbacks = [ModelCheckpoint(MODEL_WEIGHT_FILE, monitor='val_acc', save_best_only=True)]
# 一批一批读取数据进行训练
history = model.fit_generator(
    train_generator,
    callbacks = callbacks,
    samples_per_epoch = NB_TRAIN_SAMPLES,
    nb_epoch = NB_EPOCH,
    validation_data=validation_generator,
    nb_val_samples = NB_VALIDATION_SAMPLES
)

# 打印信息
acc = pd.DataFrame({
    'epoch':[i+1 for i in history.epoch],
    'training':history.history['acc'],
    'validation': history.history['val_acc']
})
ax = acc.ix[:,:].plot(x='epoch', figsize={5,8}, grid=True)
ax.set_ylabel('accuracy')
ax.set_ylim([0.7, 1.0])

max_val_acc, idx = max((val, idx) for (idx, val) in enumerate(history.history['val_acc']))
print("Maximum accuracy at epoch",'{:d}'.format(idx+1),'=','{:.4f}'.format(max_val_acc))
```

### 循环神经网络--情感分析

```python
import jieba  # 分词包
import numpy
import codecs # 提供的open方法来指定打开的文件的语言编码，它会在读取的时候自动转换为内部unicode
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
from wordcloud import WordCloud # 词云包
matplotlib.rcParams['figure.figsize'] = (10.0, 5.0)

# 读取停用词
stopwords = []
for line in open('data/stopWord.txt'):
    stopwords.append(line.strip())
    
# 定义数据读取函数，读取评论数据
def read_file(in_f, sentiment, stopwords, words, sentences):
    for line in open(in_f):
        try:
            segs = jieba.lcut(line.strip())
            # 停用词过滤
            segs = [word for word in segs if word not in stopwords and len(word)>1]
            # 记录词语 extend 一次性追加多个元素
            words.extend(segs)
            # 添加（分次评论，情感）的元组
            sentences.append((segs, sentiment))
        except:
            print(line)
            continue
            
# 读取数据
words = []
sentences = []
# 好评数据
sentiment = 1
read_file('data/1000_pos.txt', 1, stopwords, words, sentences)
# 差评数据
sentiment = 0
read_file("data/1000_neg.txt", 0, stopwords, words, sentences)
```

数据分析

```python
# 统计词语出现次数
words_df = pd.DataFrame({'评论词语':words})
words_stat = words_df.groupby(by=['评论词语'])['评论词语'].agg({'计数':numpy.size})
words_stat = words_stat.reset_index().sort_values(by=['计数'], ascentding=False)
```

词云可视化

```python
wordcloud = WordCloud(font_path='data/simhei.ttf', 
                      background_color='black', 
                      max_font_size=80)
word_frequence = {x[0]:x[1] for x in words_stat.head(1000).values}
wordcloud = wordcloud.fit_words(word_frequence)
plt.imshow(wordcloud)
```

RNN解决方案

```python
from sklearn.feature_extraction.text import CountVectorizer  # 词频编码
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM
from sklearn.model_selection import train_test_split
from keras.utils.np_utils import to_catigorical
import re
import json
import pandas as pd

tokenizer = Tokenizer(nb_words=2500, split=' ')
tokenizer.fit_on_texts(x)
X = tokenizer.text_to_sequences(x)  # 转换成稀疏向量，维度为2500
X = pad_sequences(X)  # 向量长度补全？

# 设定embedding维度等超参数
embed_dim = 16
lstm_out = 100
batch_size = 32

# 构建LSTM网络完成情感分析
model = Sequential()
model.add(Embedding(2500, embed_dim, input_length=X.shape[1], dropout=0.2))
model.add(LSTM(lstm_out, dropout_U=0.2, dropout_W=0.2))
model.add(Dense(2, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

Y = pd.get_dummies(pd.DataFrame({'label':[str(target) for target in y]})).values
X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=0.1, 
                                                      random_state=2018)

# 拟合与训练模型
model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=10)

# 结果评估
score, acc = model.evaluate(X_valid, Y_valid, verbose=2, batch_size=batch_size)
print('Logloss损失：%.2f' %score)
print('验证机的准确率：%.2f' %acc)
```

