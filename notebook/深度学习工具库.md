tensorflow分布式训练

https://blog.csdn.net/hjimce/article/details/61197190?tdsourcetag=s_pctim_aiomsg



## 第一章 Caffe 工具库



官网地址：caffe.berkeleyvision.org

安装：

ubuntu1.7以上可直接安装

1.7以下版本则下载源码安装

​	首先拷贝Makefile.config.example一份 并改名为Makefile.config

​	vim Makefile.config，可以看到对应的配置关于CUDA，GPU环境的地址，基本的设定，依赖到的一些工具库或者library，地址等等，比如只想编译CPU的版本，是否要和python工具一起编译

```
# make all -j32
```

`-j32`指做并行编译 

编译过之后会在目录下生成tools文件夹，里面存放一些工具；在build/tools/文件夹下会有编译好的一些工具，在文件目录下执行`./caffe` 可以进入命令行工具；

`# ./extract_features `会有该工具的说明

`# ./convert_imageset`格式转换，数据不是从原始形态读进来的，会转存到`leveldb`,`lmdb`当中





在caffe目录下的example文件夹下有例子，比如mnist

比如`train_lenet.sh` 是一个shell脚本， 利用caffe命令直接做训练

```
set -e
./build/tools/caffe train --solver=examples/mnist/lenet_solver.prototxt $@
~
~
..
```

然后再打开`lenet_solver.prototxt`

```
net: "examples/mnist/lenet_train_test.prototxt" 
```

表示引号当中的文件规定网络的结构

```
test_iter: 100
test_interval: 500
```

规定迭代轮次，每经过500次训练进行一次测试，每次测试100个样本

```
base_lr:0.01  //规定整个网络的学习率，还要和单层的学习率做乘法才能得到最终的学习率
momentum: 0.9  //momentum超参数
weight_decay: 0.0005   //衰减率
lr_policy:"inv"  //学习率的变化规则，如何衰减
solver_mode: GPU   //使用GPU完成训练
snapshot: 5000  //每隔5000存储一次模型
snapshot_prefix: "examples/mnist/lenet"    //模型文件名前缀
type: "Adam"
display: 100	//展示信息的频次，经过多少batch显示一次 
max_iter: 60000		//最多的迭代轮次
gamma: //lr衰减系数
stepsize: //多久进行一次lr衰减

```

`lenet_train_test.prototxt` 规定了网络结构

```
name: "LeNet"
layer{
    name: "mnist"     //这一层的名字
    type: "Data"	//层类型
    top: "data"		//输出数据
    top: "label"	//输出标签
    include {
        phase: TRAIN			//该层训练阶段使用
    }
    transform_param {
        scale: 0.00390625		// 幅度缩放，1/225 
    }
    data_param {
        source: "examples/mnist/mnist_train_lmdb" 	//数据来源 
        batch_size:64
        backend: LMDB
    }
}
layer {
    name: "mnist"
    type: "Data"
    top: "data"
    top: "label"
    include {
        phase: TEST
    }
    transform_param {
    	scale: 0.00390625
    }
    data_param {
        source: "examples/mnist/mnist_test_lmdb"
        batch_size: 100
        backend: LMDB
    }
}
layer {
    name: "conv1"
    type: "Convolution"
    bottom: "data"	//输入
    top: "conv1"	//输出
    param {
        lr_mult: 1		//weight的学习率， 与全局的学习率相乘即为最终的学习率
    }
    param {
        lr_mult: 2		//bias的学习率，与全局的学习率相乘即为最终的学习率
    }
    convolution_param {
        num_output: 20
        kernel_size: 5
        stride: 1
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
        }
    }
}
layer {
    name: "pool1"
    type: "Pooling"
    bottom: "conv1"
    top: "pool1"
    pooling_param {
        pol: MAX
        kernel_size: 2
        stride:2
    }
}
layer {
    name: "conv2"
    type: "Convolution"
    bottom: "pool1"	//输入
    top: "conv2"	//输出
    param {
        lr_mult: 1		//weight的学习率， 与全局的学习率相乘即为最终的学习率
    }
    param {
        lr_mult: 2		//bias的学习率，与全局的学习率相乘即为最终的学习率
    }
    convolution_param {
        num_output: 50
        kernel_size: 5
        stride: 1
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
        }
    }
}
...
layer {
    name: "ip2"
    type: "InnerProduct"	//全连接层
    bottom: "ip1"
    top: "ip2"
    param {
        lr_mult: 1
    }
    param {
        lr_mult: 2
    }
    inner_product_param {
        num_output: 10   //10分类结果
        weight_filler {
            type: "xavier"
        }
        bias_filler {
            type: "constant"
        }
    }
}
layer {
    name: "accuracy"
    type: "Accuracy"
    bottom: "ip2"
    bottom: "label"
    top: "accuracy"
    include {
        phase: TEST
    }
}
layer {
    name: "loss"
    type: "SoftmaxWithLoss"
    bottom: "ip2"
    bottom: "label"
    top: "loss"
}
```



`caffe/data`文件夹下已经有 mnsit数据集文件夹

里面有

```
get_minst.sh t10k-image-idx3-ubyte t10k-labels-idx1-ubyte train-image-idx3-ubyte train-labels-idx1-ubyte
```

通过脚本从网上拉下来的数据

通过`bash get_mnist.sh` 来执行





在执行例子进行训练之前要运行`create_mnist.sh`， 将数据转成lmdb形式

```
set -e
EXAMPLE=examples/mnist
DATA=data/mnist
BUILD=build/examples/mnist

BACKEND="lmdb"

echo "Creating ${BACKEND}..."

rm -rf $EXAMPLE/mnist_train_${BACKEND}
rm -rf $EXAMPLE/mnist_test_${BACKEND}

$BUILD/convert_mnist_data.bin $DATA/train-image-idx3-ubyte \
  $DATA/train-labels-idx1-ubyte $EXAMPLE/mnist_train_${BACKEND} --backend=${BACKEND}
$BUILD/convert_mnist_data.bin $DATA/t10k-image-idx3-ubyte \
  $DATA/t10k-labels-idx1-ubyte $EXAMPLE/mnist_test_${BACKEND} --backend=${BACKEND}

echo "Done."

```

运行脚本

```
bash create_mnist.sh
。/examples/mnist/create_mnist.sh
```

执行训练

```
./examples/mnist/train_lenet_adam.sh
```

训练之后会生成模型文件`lenet_iter_10000.caffemodel`



数据转化`./build/tools/convert_imageset.bin  `

`可后续加参数-backend lmdb` 

```
convert_imageset [FLAGS] ROOTFOLDER(图像存储路径)/LISTFILE（绝对路径和类别） DB_NAME(数据库文件名称)
```



总结： 使用CAFFE完成神经网络训练操作步骤（命令行的方式）：

- 原始数据转换：写数据转换脚本 转换成lmdb, leveldb， 原始数据是图片如（jpg  png  tif）等大量散碎文件，lmdb,leveldb是特殊的二进制数据文件，对计算机读写操作有极大的优化

```
// HDFS-5数据格式输入的示例（来自caffe官方）
name: "LogisticRegressionNet"
layer {
    name: "data"
    type: "HDF5Data"
    top: "data"
    top: "label"
    include {
        phase: TRAIN
    }
    hdf5_data_param {
        source: "examples/hdf5_classification/data/train.txt"
        batch_size: 10
    }
}
```



- 定义网络层：  按指定格式写prototxt文件

 ```
name: "LogisticRegressionNet"
layers {
    top: "data"			//定义输出数据
    top: "label"		//定义层输出数据
    name: "data"
    type: HDF5_DATA
    hdf5_data_param {
        source: "examples/hdf5_classification/data/train.txt"
        batch_size: 10
    }
    include {
        phase: TRAIN
    }
}
layers {
    bottom: "data"
    top: "fc1"
    name: "fc1"
    type: INNER_PRODUCT  //全连接层
    blobs_lr: 1     //w 学习率
    blobs_lr: 2		//b 学习率
    weight_decay: 1		//Regularization weight
    weight_decay: 0		//... bias
    inner_product_param {
        num_output: 2
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}
layers {
    bottom: "fc1"
    bottom: "label"
    top: "loss"
    name: "loss"
    type: SOFTMAX_LOSS
}
 ```

可能出现的问题：

prototxt文件可能因为模型较大，层次较深而变得十分臃肿

不能文件组合，复杂网络很难定义

直到caffe2，才有RNN的网络定义版本



- solver定义：按指定格式写prototxt文件，定义优化参数和算法

  

  

- 训练：写一个训练脚本

```
./build/tools/caffe train \
	gpu 0 \			// gpu设备号
	model path/to/trainval.prototxt	\	// 网络模型设计文件
	solver path/to/solver/prototxt \	// 模型优化文件
	weight path/to/pretrained_weights.caffemodel	//预训练模型
```



项目示例

caffe里提供modelzoo里有非常多的训练好的模型

新加层次调大学习率

```
layers {
    name: "fc8_oxford102"
    type: INNER_PRODUCT
    bottom: "fc7"
    top: "fc8_oxford102"
    blobs_lr:10
    blobs_lr:20
    weight_decay:1
    weight_decay:0
    inner_product_param {
        num_output:102
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
}
layers {
    name: "loss"
    type: SOFTMAX_LOSS
    bottom: "fc8_oxford102"
    bottom: "label"
}
layers {
    name: "accuracy"
    ...
}
```

caffe-oxford102文件夹是包含以下文件

```
README.ipynb 
README.md 
VGG_S 				//
boottrap.py 		//从网上把数据下载下来的python代码
classs_labels.py 
data plots 
test.txt 
train.txt 
valid.txt
```

bootstrap.py

```python
import os
import sys
import glob
import urllib.request as rq
import tarfile
import numpy as np

def download_file(url, dest=None):
    if not dest:
        dest = 'data/' + url.split('/')[-1]
    rq.urlretrieve(url, dest)
    
# Download the oxford102 dataset into the current directory
if not os.path.exist('data'):
    os.mkdir('data')
    
    print('Sownloading images...')
    download_file('http://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flower.tgz')
    tarfile.open("data/102flower.tgz").extractall(path='data/')
    
    print("Downloading image labels...")
    download_file("http://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat")
    
    print("Downloading train/test/valid splits...")
    download_file('http://www.robots.ox.ac.uk/~vgg/data/flowers/102/setid.mat')
    
# Read .mat file containing training, testing, and validation sets.
setid = loadmat('data/setid.mat')

print(setid)
# The .mat file is 1-indexed, so we subtract one to match Caffe's convention.
idx_train = setid['trnid'][0] - 1
idx_test = setid['tstid'][0] - 1
idx_valid = setid['valid'][0] - 1

# Read .mat file containing image labels.
image_labels = loadmat('data/imagelabels.mat')['labels'][0]
# Subtract one to get 0-based labels
image_labels -= 1

files = sorted(glob.glob('data/jpg/*.jpg'))  # 读取通配符路径，排序？
labels = np.array(list(zip(files, image_labels)))

# Get current working directory for making absolute paths to images
cwd = os.path.dirname(os.path.relpath(__file__))

def write_set_file(fout, labels):
    with open(fout, 'w+') as f:
        for label in labels:
            f.write('%s/%s %s\n' % (cwd, label[0], label[1]))
            
# Images are orderd by species, so shuffle them
np.random.seed(2018)
idx_train = idx_train[np.random.permutation(len(idx_train))]
idx_test = idx_test[np.random.permutation(len(idx_test))]
idx_valid = idx_valid[np.random.permutation(len(idx_valid))]

write_set_file('train.txt', labels[idx_train, :])
write_set_file('test.txt', labels[idx_test, :])
write_set_file('valid.txt', labels[idx_valid, :])

# if not os.path.exists("AlexNet/pretrained-weights.caffemodel"):
#     print('Downloading Alexnet pretrianed wights...')
#     download_file('http://s3.amazonaws.com/jgoode/cannaid/bvlc_ref...cafemodel',
#                   'AlexNet/pretrained0weights.caffemodel')

if not os.path.exists("AlexNet/pretrained-weights.caffemodel"):
    print('Downloading Alexnet pretrianed wights...')
    download_file('http://www.robots.ox.ac.uk/~vgg/software/deep_eval/releases/bvlc/VGG_CNN_S.cafffemodel','VGG_S/pretrained-weights.caffemodel')
```

VGG_S文件夹下有以下文件

```
deploy.prototxt
log-flipped.txt
log.txt
pretrained-weights.caffemodel
solver.prototxt
train_val.prototxt 
```

通过bootstrap.py 下载下来的data 目录下

```
102flowers.tgz
imagelabels.mat
jpg
setid.mat
```

通过bootstrap.py构建的train.txt test.txt valid.txt 格式为

“图片路径加文件名称  类别号”

执行训练

```
../caffe/build/tools/caffe train -solver sover.prototxt -weights pretrained-weights.caffemodel -gpu 0
```

网络结构配置文件定义了，均值化要根据一个均值配置文件，所以提示缺少均值文件

```
bash get_ilsvrc_aux.sh
之后下载下来imagenet_mean.binaryproto均值文件
cp src dest  
拷贝到当前目录下

```

发现内存占用太大

查看显存使用情况

```
nvidia-smi
```

关闭多余进程

```
kill -9 5340(PID号)
```

减少全连接层



使用caffe工具库抽取特征

命令方式：

1. Caffe 提供了为了提取特征而设计的网络结构样例， 仿照它写一个特征抽取网络(./examples/feature_extraction/imagenet_val.prototxt)
2. 调用Caffe框架里有特征抽取的命令（./build/tools/extract_features.bin)

```
extract_features.bin \
pretrained_net_param \ # 实现训练好的网络参数，具体的文件是bvlc_reference_caffemodel(caffe龚恒自带)
feature_extraction_proto_file  \ # 网络配置原型就是上面更改的.prototxt文件
extract_feature_blob_name1[,name2,...] \ # 表示特顶层的特征，比如fc7,conv5,pool5,这个需要和上面的.prototxt文件定义的一致
save_feature_dataset_name1[,name2,...] \ # 表示需要存储提取到的特征目录，这个目录由程序自动创建
num_mini_batches \ # 为批次处理个数，这个乘以.prototxt里面配置的batch_size得到的就是总共需要提取的图片的个数
db_type \ # 表示提取到的特征按照什么方式存储，目前有两种方式，lmdb和leveldb
[CPU/GPU][DEVICE_ID=0]  # 默认CPU，后面可以指定GPU以及具体的GPU个数
```

3. 对某一层的特征，可直接保存下来

```
feat_fc6 = net.blobs['fc6].data[0]
feat_fc6.shape = (4096,1)
row_feat_fc6 = numpy.transpose(feat_fc6)
numpy.savetxt(./caffe/examples/_temp/ +"features.txt", row_feat_fc6)
scipy.io.savemat(./caffe/examples/_temp/ + "feature.mat", {'feature':row_feat_fc6})
```



抽取特征的过程

执行`./build/tools/extract_features.bin` 可以看到使用方法介绍，例

```
./build/tools/extract_features.bin examples/mnist/lenet_iter_10000.caffemodel examples/mnist/lenet_train_test.prototxt ip2 examples/features 10 lmdb GPU 0
```







## 第二章  Keras 工具库

高层封装神经网络API

纯Python编写

利用tensorflow Theano  CNTK  mxnet作为后端计算，通过 keras.json文件配置

引入库， 初始化“模型架子”

```python
from keras.models import Sequential
model = Sequential()
```

通过add来添加层

```python
from keras.layers import Dense, Activation

model.add(Dense(units=64, input_dim=100))  # 全连接层
model.add(Activation('relu'))   # 激活层
model.add(Dense(units=10))
model.add(Activation('softmax'))
```

通过compile来编译模型

```python
model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])
```

编译模型时必须指明损失函数和优化器，如果你需要的话，也可以自己定制损失函数。Keras里也封装了很多优化器和损失函数

```python
from keras.optimizers import SGD
model.compile(loss='categorical_crossentropy', optimizer=SGD(LR=0.01, momentum=0.9, nesterov=True))
```

训练模型

```
model.fit(x_train, y_train, epochs=5, batch_size=32)
```

手动一批一批数据训练

```
model.train_on_batch(x_batch, y_batch)
```

在测试集上评估效果

```
loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)
```

实际预测

```
classes = model.predict(x_test, batch_size=128)
```





### Keras 序贯模型

简单的堆叠

可以通过向Sequential 模型传递一个layer的list来构建序列模型，或者通过.add()方法一个个的将layer加入模型

```python
# 一次性构建
from keras.models import Sequential
from keras.layers import Dense, Activation

model = Sequential([
    Dense(32, input_dim=784),
    Activation('relu'),
    Dense(10),
    Activation('softmax'),
])
```

手动添加

```python
model = Sequential()
model.add(Dense(32, input_shape=(784,)))
model.add(Activation('relu'))
```

告诉模型输入数据的维度



编译模型：`compile`接收三个参数：

- 优化器optimizer
- 损失函数loss   https://keras-cn.readthedocs.io/en/latest/other/objectives/
- 指标列表metrics

```python
# 多分类问题
model.compile(
    optimizer='rmsprop',
    loss='categorical_crossentropy',
    metrics=['accuracy']
)
# 二分类问题
model.compile(
    optimizer='rmsprop',
    loss='binary_crossentropy',
    metrics=['accuracy']
)
# 回归问题
model.compile(
    optimizer='adagrad',
    loss='mse'
)

# 自定义metrics
import keras.backend as K

def mean_pred(y_true, y_pred):
    return K.mean(y_pred)

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy', mean_pred])
```

训练

如果一次性读进内容进行建模

```python
# 构建与编译模型
model = Sequential()
model.add(Dense(32, activation='relu', imput_dim=100))
model.add(Dense(1, activation='sigmoid'))
model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])

# 查出数据
import numpy as np
data = np.random.random((1000, 100))
labels = np.random.randint(2, size=(1000, 1))

# 训练与数据拟合
history = model.fit(data, labels, epochs=10, batch_size=32)
```

如果你的数据量很大， 你可能要用到fit_generator

```python
def generate_array_from_file(path):
    while 1:
        f = open(path)
        for line in f:
            x, y = process_line(line)  # 自己实现，把文件地址转换成输入和标签
            img = load_images(x)
            yield (img, y)  # 返回结果，且不中断循环
        f.close()
        
model.fit_generator(generate_arrays_from_file('/my_file.txt'), samples_per_epoch=10000,
                    nb_epoch=10)
```

序贯模型的例子

多层感知机

```python
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation
from keras.optimizers import SGD

# Generate dummy data
import numpy as np
x_train = np.random.random((1000, 20))
y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000,1)), num_classes=10)
x_test = np.random.random((100,20))
y_test = keras.utils.to_categorical(np.random.randint(10, size=(100,1)), num_classes=10)

model = Sequential()
model.add(Dense(64, activation='relu', input_dim=20))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

model.fit(x_train, y_train, epochs=20, batch_size=128)
score = model.evaluate(x_test, y_test, batch_size=128)
```

卷积神经网络

```python
import numpy as np
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.optimizers import SGD

x_train = np.random.random((100, 100, 100, 3))
y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)
x_test = np.random.random((20, 100, 100, 3))
y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)

model = Sequential()
# input: 100x100 images with 3 channels
# this applies 32convolution filters of size 3x3 each.
model.add(Conv2D(32, (3,3), activation='relu', input_shape=(100, 100, 3)))
model.add(Conv2D(32, (3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3,3), activation='relu'))
model.add(Conv2D(64, (3,3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=32, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=32)
```

循环神经网络

```python
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.layers import Embedding
from keras.layers import LSTM

model = Sequential()
model.add(Embedding(max_features, output_dim=256))
model.add(LSTM(128))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
model.fit(x_train, y_train, batch_size=16, epochs=10)
score = model.evaluate(x_test, y_test, batch_size=16)
```

### 函数式模型

MLP的例子

```python
from keras.layers import Input, Dense
from keras.models import Model

inputs = Input(shape=(784,))
x = Dense(64, activation='relu')(inputs)
x = Dense(64, activation='relu')(x)
predictions = Dense(10, activation='softmax')(x)

model = Model(inputs=inputs, outputs=predictions)
model.compile(optimizer='rmsprop',
             loss='categorical_crossentropy',
             metrics=['accuracy'])
model.fit(data, labels)
```

当你调用一个模型时，你不仅仅重用了它的结构，也重用了他的权重

```python
x = Input(shape=(784,))
# 给一个x，就会复用上面的模型，得到y
y = model(x)
```

更复杂的多输入多输出模型

考虑这样一个模型。我们希望预测Twitter上一条新闻会被转发和点赞多少次。 模型的主要输入是新闻本身，也就是一个词语的序列。但我们还可以拥有额外的输入，如新闻发布的日期等。 这个模型的损失函数将由两部分组成，辅助的损失函数评估仅仅基于新闻本身做出预测的情况，主损失函数评估基于新闻和额外信息的预测的情况，即使来自主损失函数的梯度发生弥散，来自辅助损失函数的信息也能够训练`Embeddding`和`LSTM`层。在模型中早点使用主要的损失函数是对于深度网络的一个良好的正则方法。 

主要的输入接收新闻本身，即一个整数的序列（每个整数编码了一个词）。这些整数位于1到10000之间（即我们的字典有10000个词）。这个序列有100个单词。 

```python
from keras.layers import Input, Embedding, LSTM, Dense
from keras.models import Model

# Headline input: meant to receive sequence of 100 integers, between 1 and 10000.
# Note that we can name any layer by passing it a "name" argument.
main_input = Input(shape=(100,), dtype='int32', name='main_input')

# This embedding layer will encode the input sequence
# into a sequence of dense 512-dimensional vectors.
x = Embedding(ouput_dim=512, input_dim=10000, input_length=100)(main_input)

# A LSTM will transform the vector sequence into a single vector, containing information about the entire sequence.
lstm_out = LSTM(32)(x)
```

然后我们插入一个额外的损失，使得即使在主损失很高的情况下，LSTM和Embedding层也可以平滑训练。

```python
auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(lstm_out)
```

再然后，我们将LSTM与额外的输入数据串联起来组成输入，送入模型：

```python
auxiliary_input = Input(shape=(5,), name='aux_input')
x = keras.layers.concatenate([lstm_out, auxiliary_input])

# We stack a deep densely-connected network on top
x = Dense(64, activation='relu')(x)
x = Dense(64, activation='relu')(x)
x = Dense(64, activation='relu')(x)

# And finally we add the main logistic regression layer
main_output = Dense(1, activation='sigmoid', name='main_output')(x)
```

最后我们定义整个2输入2输出模型

```python
model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])
```

模型定义完成，下一步编译模型，我们给额外的损失赋值0.2的权重。我们可以通过关键字参数`loss_weights`或者`loss`来为不同的输出设置不同的损失函数或权值。这两个参数均可为Python的列表或字典。这里我们给loss传递单个损失函数，这个损失函数会被应用于所有输出上。

```python
model.compile(opimizer='rmsprop', loss='binary_crossentropy', loss_weights=[1.0, 0.2])
```

传递训练数据和目标值训练模型

```python
model.fit([headline_data, additional_data], [labels, labels], epochs=50, batch_size=32)
```

因为我们的输入和输出是被命名过的（在定义时传递了“name”参数），我们也可以用下面的方式编译和训练模型

```python
model.compile(optimizer='rmsprop',
             loss={'main_output':'binary_crossentropy', 
                   'aux_output':'binary_crossentropy'},
             loss_weights={'main_output':1.0, 'aux_output':0.2})
model.fit({'main_input':headline_data, "aux_input":additional_data},
         {'main_output':labels, 'aux_output':labels},
         epochs=50, batch_size=32)
```

Google inception

```python
from keras.layers import Conv2D, MaxPooling2D, Input

input_img = Input(shape=(3,256, 256))

tower_1 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)
tower_1 = Conv2D(64, (3,3), padding='same', activation='relu')(tower_1)

tower_2 = Conv2D(64, (1,1), padding='same', activation='relu')(input_img)
tower_2 = Conv2D(64, (5,5), padding='same', activation='relu')(tower_2)

tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_img)
tower_3 = Conv2D(64, (1,1), padding='same', activation='relu')(tower_3)

output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)
```

残差网络 ResNet

```python
from keras.layers import Conv2D, Input

# input tensor for a 3-channel 256x256 image
x = Input(shape=(3,256,256))
# 3x3 conv with 3output channels (same as input channels)
y = Conv2D(3, (3,3), padding='same')(x)
# this return x + y
z = keras.layers.add([x, y])
```

共享视觉模型

该模型再两个输入上重用了图像处理模型，用来判别两个MNIST数字是相同数字

```python
from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten
from keras.models import Model

# First define the vision modules
digit_input = Input(shape=(1, 27, 27))
x = Conv2D(64, (3,3))(digit_input)
x = Conv2D(64, (3,3))(x)
x = MaxPooling2D((2,2))(x)
out = Flatten()(x)

vision_model = Model(digit_input, out)

# Then define the tell-digits-apart model
digit_a = Input(shape=(1, 27, 27))
digit_b = Input(shape=(1, 27, 27))

# The vision model wii be shared, weights and all
out_a = vision_model(digit_a)
out_b = vision_model(digit_b)

concatenated = keras.layers.concatenate([out_a, out_b])
out = Dense(1, activation='sigmoid')(concatenated)

classification_model = Model([digit_a, digit_b], out)
```

视频问答模型

在针对一幅图片使用自然语言进行提问时，该模型能够提供关于该图片的一个单词的答案

这个模型将自然语言的问题和图片分别映射为特征向量，将二者合并后训练一个logistic回归层，从一系列可能的答案中挑选一个。

```python
from keras.layers import Conv2D, MaxPooling2D, Flatten
from keras.layers import Input, LSTM, Embedding, Dense
from Keras.layers import Model, Sequential

# first, let's define a vision model using a Sequential model.
# This model will encode an image into a vector
vision_model = Sequential()
vision_model = add(Conv2D(64, (3,3), activation='relu', padding='same', 
                          input_shape(3,224,224)))
```

