# Hadoop和Map-Reduce

## Hadoop历史

Hadoop雏形开始于2002年得Apache得Nutch，Nutch是一个开源Java实现的搜索引擎，它提供了我们运行自己的搜索引擎所需的全部工具。包括全文搜索和Web爬虫。

随后在2003年Google发表了一篇技术学术论文谷歌文件系统（GFS）。GFS就是Google File System，Google公司为了存储海量搜索数据而设计的专用文件系统。

2004年Nutch创始人Doug Cutting基于Google的GFS论文实现了分布式文件存储系统名为NDFS。

2004年Google又发表了一篇技术学术论文MapReduce。MapReduce是一种编程模型，用于大规模数据集（大于1TB）的并行分析运算。

2005年Doug Cutting又基于MapReduce，在Nutch搜索引擎上实现了该功能。

2006年，Yahoo雇佣了Doug Cutting，Doug Cutting将NDFS和MapReduce升级命名为Hadoop，Yahoo开建了一个团队给Doug Cutting专门研究发展Hadoop。

Google和Yahoo对Hadoop的贡献功不可没。

## Hadoop核心

Hadoop的核心是HDFS和MapReduce，而两者只是理论基础，不是具体可使用的高级应用，Hadoop生态又很多经典子项目，比如HBase、Hive等，这些都是基于HDFS和MapReduce发展出来的。想要了解Hadoop，就必须知道HDFS和MapReduce是什么。

## HDFS

HDFS（Hadoop Distributed File System, Hadoop分布式文件系统），它是一个高度容错性的系统，适合部署在廉价的机器上，HDFS能提供高吞吐量的数据访问，适合那些有着超大数据集（Large data set）的应用程序。

HDFS的设计特点是：

**大数据文件**，非常适合上T级别的大文件或者一堆大数据文件的存储，如果文件只有几个G甚至更小就没啥意思了。

**文件分块存储**，HDFS会将一个完整的大文件平均分块存储到不同的计算器上，它的意义在于读取文件时可以同时从多个主机取不同区块的文件，多主机读取比单主机读取效率要高得多。

**流式数据访问**，一次写入多次读写，这种模式和传统文件不同，它不支持动态改变文件内容，而是要求让文件一次写入就不做变化，要变化也只能在文件末添加内容。

**廉价硬件**，HDFS可以应用在普通PC机上，这种机制能够让一些公司用几十台廉价的计算机就可以撑起一个大数据集群。

**硬件故障**，HDFS认为所有计算机都有可能出问题，为了防止每个主机失效，读取不到该主机的块文件，它将同一个文件的块副本分配到其他某几个主机上，如果其中一台主机失效，可以迅速找另一块副本取文件。

### HDFS的关键元素

**Block**：将一个文件进行分块，通常是64M。大文件的存储会被分割为多个block进行存储。每个block会在多个datanode上存储多份副本，默认为3份（这些设置都能够通过配置文件进行更改）

**NameNode**：保存整个文件系统的目录信息、文件信息及分块信息，这是由唯一一台主机专门保存，当然如果这台主机出错，NameNode就失效了。在Hadoop2.*上开始支持activity-standy模式，如果主NameNode失效，启动备用主机运行NameNode。主要负责存储一些metadata信息，主要包括文件目录、block和文件对应关系，以及block和datanode的对应关系

**DataNode**：分布在廉价的计算机上，用于存储Block块文件。高容错性大部分在datanode上实现的（还有一部分容错性是体现在namenode和secondname，还有jobtracker的容错等）。

​     ![](/images/hadoop01.png)                         

### hdfs设计思路

HDFS设计之初就是针对超大文件的存储的，小文件不会提高访问和存储速度，反而会降低；其次它采用了最高效的访问模式，也就是经常所说的流式数据访问，特点就是一次写入多次读取；再有就是它运行在普通的硬件之上的，即使硬件故障，也就是通过容错来保证数据的高可用。

### HDFS优点

+ 高吞吐访问：HDFS的每个block分布在不同的rack上，在用户访问时，HDFS会计算使用最近和访问量最小的服务器给用户提供。由于block在不同的rack上都有备份，所以不再是单数据访问，所以速度和效率是非常快的。另外HDFS可以并行从服务器集群中读写，增加了文件读写的访问带宽。
+ 高容错性：系统故障时不可避免的，如何做到故障之后的数据恢复和容错处理是至关重要的。HDFS通过多方面保证数据的可靠性，多份复制并且分布到物理位置不同的服务器上，数据校验功能、后台的连续自检数据一致性功能，都是为高容错提供了可能。
+ 容量扩充：因为HDFS的block信息存放到namenode上，文件的block分布在datanode上，当扩充的时候，仅仅添加datanode数量，系统可以在不停止服务的情况下做扩充，不需要人工干预。

### HDFS常见命令

显示/下的所有文件夹信息

## MapReduce

通俗说MapReduce是一套从海量源数据提取分析元素最后返回结果集的编程模型，将文件分布式的存储到硬盘是第一步，而从海量数据中提取分析我们需要的内容就是MapReduce需要做的事情了。

下面以一个计算海量数据最大值为例：一个银行有上亿储户，银行希望找到存储金额最高的金额是多少，按照传统的计算方式，我们会这样：

```java
Long moneys[] …
Long max=0L;
for(int i=0;i<moneys.length;i++){
       if(moneys[i]>max){
              max = moneys[i];
       }
}
```

如果计算的数组长度少的话，这样实现是不会又问题的，但是面对海量数据的时候就会有问题。

MapReduce会这样做：首先数字是分布存储在不同块中的，以某几个块为一个map，计算出map中最大的值，然后将每个map中的最大值做Reduce操作，Reduce再取最大值给用户。

![](/images/hadoop02.jpg)



 MapReduce的基本原理就是：将大的数据分析分成小块逐个分析，最后再将提取出来的数据汇总分析，最终获得我们想要的内容，当然怎么分块分析，怎么做Reduce操作非常复杂，hadoop已经提供了数据分析的实现，我们只需要编写简单的需求命令即可达成我们想要的数据。

**总结**

总的来说，Hadoop适合用于大数据存储和大数据分析的应用，适合于服务器几千台到几万台的机群运行，我们支持PB级的存储容量

Hadoop典型应用有：搜索，日志处理，推荐系统，数据分析，视频图像分析，数据保存等。